{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MasterGAN_Sept_17.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q7opKehF2o6s",
        "btmnF_Ev2sE2",
        "3ekYonDj5mEW",
        "RHuPwrHIamti"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7tFYLK_3QdG"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49gQTxLP8DPF"
      },
      "source": [
        "width, height = 256, 256"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMKnO8ig27mB"
      },
      "source": [
        "! pip install -q kaggle\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Bp98tcdAh9Wi",
        "outputId": "ad9c008a-d60b-4516-c70e-8e47576ec505"
      },
      "source": [
        "#files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf7f0dd9-322d-4144-9888-25850c0fcf51\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bf7f0dd9-322d-4144-9888-25850c0fcf51\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"larada\",\"key\":\"2d01da7eff2b426ae0379bf5729939e5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQHSjcHlgyc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1eda34c-38f8-4dd2-9d76-51cd12c7fe34"
      },
      "source": [
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              235KB  2021-09-15 20:16:36          12285  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           7441  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           3035  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-07-03 18:37:20           2905  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1915  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23           1139  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            934  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1374  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            333  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            895  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            824  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            344  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            194  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            140  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            139  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            129  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         150486  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         143767  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          26955  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          21764  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9orQHeZ2Toy"
      },
      "source": [
        "# Download Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7opKehF2o6s"
      },
      "source": [
        "# BIG 2015"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzzaJTEX2oU4",
        "outputId": "5f5d5653-ed57-46ad-ceb3-49bd00ebb5c3"
      },
      "source": [
        "! kaggle competitions download -c malware-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "403 - Forbidden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6MfsDef3IR3"
      },
      "source": [
        "local_zip = '/content/BIG.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/BIG2015')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btmnF_Ev2sE2"
      },
      "source": [
        "# MalImg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlCh6dGlcmAs",
        "outputId": "79fcf7a7-dbbf-4e0f-8e3e-d7d657730bab"
      },
      "source": [
        "! kaggle datasets download -d keerthicheepurupalli/malimg-dataset9010"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading malimg-dataset9010.zip to /content\n",
            " 99% 1.20G/1.21G [00:11<00:00, 129MB/s]\n",
            "100% 1.21G/1.21G [00:11<00:00, 113MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRK1WWqI3YZp"
      },
      "source": [
        "local_zip = '/content/malimg-dataset9010.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/MalImg')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8cWT_fAdxez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "3650cbcb-31fd-4ea5-f206-32d3f7d68a86"
      },
      "source": [
        "import os\n",
        "from os.path import join as pjoin\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "data_dir  = '/content/MalImg/dataset_9010/dataset_9010/malimg_dataset/train'\n",
        "binary_dir = '/content/bin_MalImg/train'\n",
        "\n",
        "\n",
        "def savefile(guy,i,binary_file):\n",
        "    save_dir = pjoin(binary_dir, guy)  # the save address\n",
        "    if not os.path.exists(save_dir):  # if the save address doesn't exsit, create\n",
        "        os.makedirs(save_dir)\n",
        "    name_binary = \"{}/{}.npy\".format(save_dir,i[:-4])#the name of .npy file\n",
        "    np.save(name_binary,binary_file)\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    for guy in os.listdir(data_dir):#read the name of img_family in the data_dir\n",
        "        family_dir = pjoin(data_dir,guy)#the malware family document direciton\n",
        "        for i in os.listdir(family_dir):#read the img name in this family\n",
        "            img_dir= pjoin(family_dir,i)#img address\n",
        "            img = cv2.imread(img_dir,cv2.IMREAD_GRAYSCALE)#read the img\n",
        "            img_1D = img.flatten()\n",
        "            savefile(guy,i,img_1D)\n",
        "\n",
        "load_data(data_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ec4e5cbc2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msavefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_1D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9ec4e5cbc2b0>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mguy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#read the name of img_family in the data_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfamily_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mguy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#the malware family document direciton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#read the img name in this family\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/MalImg/dataset_9010/dataset_9010/malimg_dataset/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ekYonDj5mEW"
      },
      "source": [
        "# Goodware dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atn4-bx-5h3T",
        "outputId": "69dbfc64-e3fd-4b23-dd98-c02bed80447e"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "     https://download.wetransfer.com/eugv/48b7cd3775c1a521c8f7d03ab991781720210912103653/e95f4256bafa9735bcec91838495a3e2f6b4c9f3/executables.zip?token=eyJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2MzE0NTQ4MDUsImV4cCI6MTYzMTQ1NTQwNSwidW5pcXVlIjoiNDhiN2NkMzc3NWMxYTUyMWM4ZjdkMDNhYjk5MTc4MTcyMDIxMDkxMjEwMzY1MyIsImZpbGVuYW1lIjoiZXhlY3V0YWJsZXMuemlwIiwid2F5YmlsbF91cmwiOiJodHRwOi8vc3Rvcm0taW50ZXJuYWwuc2VydmljZS5ldS13ZXN0LTEud2V0cmFuc2Zlci5uZXQvYXBpL3dheWJpbGxzP3NpZ25lZF93YXliaWxsX2lkPWV5SmZjbUZwYkhNaU9uc2liV1Z6YzJGblpTSTZJa0pCYUhOTGQyWTRiMGhvWVNJc0ltVjRjQ0k2SWpJd01qRXRNRGt0TVRKVU1UUTZNRE02TWpVdU1EQXdXaUlzSW5CMWNpSTZJbmRoZVdKcGJHeGZhV1FpZlgwLS05ZDczMmI0ODNiY2ZiZDM0N2Y1YzgyMWFkY2Q1YTFmZmM1ZmU1ZjRlZmZiNTE5YzhjYTUxOGYyYzNkM2I3NzJmIiwiZmluZ2VycHJpbnQiOiJlOTVmNDI1NmJhZmE5NzM1YmNlYzkxODM4NDk1YTNlMmY2YjRjOWYzIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL2Zyb250ZW5kLnNlcnZpY2UuZXUtd2VzdC0xLndldHJhbnNmZXIubmV0L3dlYmhvb2tzL2JhY2tlbmRcIn0sXCJmb3JtXCI6e1widHJhbnNmZXJfaWRcIjpcIjQ4YjdjZDM3NzVjMWE1MjFjOGY3ZDAzYWI5OTE3ODE3MjAyMTA5MTIxMDM2NTNcIixcImRvd25sb2FkX2lkXCI6MTMwNjI1ODAyMzZ9fSJ9.F1Emfuf53pGzLscZ8ZfcD66WpG8G0yQq1OsB41RVqfA&cf=y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The name is too long, 999 chars total.\n",
            "Trying to shorten...\n",
            "New name is executables.zip?token=eyJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2MzE0NTQ4MDUsImV4cCI6MTYzMTQ1NTQwNSwidW5pcXVlIjoiNDhiN2NkMzc3NWMxYTUyMWM4ZjdkMDNhYjk5MTc4MTcyMDIxMDkxMjEwMzY1MyIsImZpbGVuYW1lIjoiZXhlY3V0YWJsZXMuemlwIiwid2F5YmlsbF91cmwiOiJodHRwOi8vc.\n",
            "--2021-09-14 12:49:17--  https://download.wetransfer.com/eugv/48b7cd3775c1a521c8f7d03ab991781720210912103653/e95f4256bafa9735bcec91838495a3e2f6b4c9f3/executables.zip?token=eyJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2MzE0NTQ4MDUsImV4cCI6MTYzMTQ1NTQwNSwidW5pcXVlIjoiNDhiN2NkMzc3NWMxYTUyMWM4ZjdkMDNhYjk5MTc4MTcyMDIxMDkxMjEwMzY1MyIsImZpbGVuYW1lIjoiZXhlY3V0YWJsZXMuemlwIiwid2F5YmlsbF91cmwiOiJodHRwOi8vc3Rvcm0taW50ZXJuYWwuc2VydmljZS5ldS13ZXN0LTEud2V0cmFuc2Zlci5uZXQvYXBpL3dheWJpbGxzP3NpZ25lZF93YXliaWxsX2lkPWV5SmZjbUZwYkhNaU9uc2liV1Z6YzJGblpTSTZJa0pCYUhOTGQyWTRiMGhvWVNJc0ltVjRjQ0k2SWpJd01qRXRNRGt0TVRKVU1UUTZNRE02TWpVdU1EQXdXaUlzSW5CMWNpSTZJbmRoZVdKcGJHeGZhV1FpZlgwLS05ZDczMmI0ODNiY2ZiZDM0N2Y1YzgyMWFkY2Q1YTFmZmM1ZmU1ZjRlZmZiNTE5YzhjYTUxOGYyYzNkM2I3NzJmIiwiZmluZ2VycHJpbnQiOiJlOTVmNDI1NmJhZmE5NzM1YmNlYzkxODM4NDk1YTNlMmY2YjRjOWYzIiwiY2FsbGJhY2siOiJ7XCJmb3JtZGF0YVwiOntcImFjdGlvblwiOlwiaHR0cDovL2Zyb250ZW5kLnNlcnZpY2UuZXUtd2VzdC0xLndldHJhbnNmZXIubmV0L3dlYmhvb2tzL2JhY2tlbmRcIn0sXCJmb3JtXCI6e1widHJhbnNmZXJfaWRcIjpcIjQ4YjdjZDM3NzVjMWE1MjFjOGY3ZDAzYWI5OTE3ODE3MjAyMTA5MTIxMDM2NTNcIixcImRvd25sb2FkX2lkXCI6MTMwNjI1ODAyMzZ9fSJ9.F1Emfuf53pGzLscZ8ZfcD66WpG8G0yQq1OsB41RVqfA\n",
            "Resolving download.wetransfer.com (download.wetransfer.com)... 13.249.38.62, 13.249.38.46, 13.249.38.54, ...\n",
            "Connecting to download.wetransfer.com (download.wetransfer.com)|13.249.38.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 410 Gone\n",
            "2021-09-14 12:49:18 ERROR 410: Gone.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XXBIOx5h3n"
      },
      "source": [
        "local_zip = '/content/executables.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/goodware')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq9AWGZa7k2I"
      },
      "source": [
        "# Data preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDWAlFFDHScS"
      },
      "source": [
        "# ref: https://github.com/ncarkaci/binary-to-image\n",
        "import numpy as np\n",
        "import os, math\n",
        "import argparse\n",
        "from PIL import Image \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYRNqLhZwMOd"
      },
      "source": [
        "def defineColorMap():\n",
        "  rows  = 256\n",
        "  columns = 256\n",
        "  min = 0 \n",
        "  max = 256\n",
        "  step = 2\n",
        "  colormap = np.random.randint(min, max, size=rows * columns, dtype='l')\n",
        "  colormap.resize(rows,columns)\n",
        "  print(colormap)\n",
        "  print(\"\\n\\n \",colormap.shape)\n",
        "  return colormap"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcBuEvdAMDfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "541ae36e-29e3-4d8f-e0d9-f539f83a65ed"
      },
      "source": [
        "'''colormap = defineColorMap()\n",
        "R_colormap = defineColorMap()\n",
        "G_colormap = defineColorMap()\n",
        "B_colormap = defineColorMap()'''\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'colormap = defineColorMap()\\nR_colormap = defineColorMap()\\nG_colormap = defineColorMap()\\nB_colormap = defineColorMap()'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVP_2aJ2Qqr-"
      },
      "source": [
        "def readBytes (filename):\n",
        "  img_bin_data = []\n",
        "  with open(filename, 'rb') as file:\n",
        "     #this sintax is to be read as \"with the output of the function open considered as a file\"\n",
        "     # wb as in read binary\n",
        "    while True:\n",
        "      # as long as we can read one byte\n",
        "      b = file.read(1)\n",
        "      if not b:\n",
        "        break\n",
        "      img_bin_data.append(int.from_bytes(b, byteorder='big'))\n",
        "  return img_bin_data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udQnqg8XBkZy"
      },
      "source": [
        "def readBytes_fromNumpy (filename):\n",
        "  return np.load(filename)    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBwoo4x50S6N"
      },
      "source": [
        "#img_bin_data = readBytes('/content/logounirc.png')\n",
        "#print(img_bin_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ZUZKHtCD8c"
      },
      "source": [
        "#img_bin_data = readBytes_fromNumpy('/content/123.npy')\n",
        "#print(img_bin_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqZLxsFsyPOp"
      },
      "source": [
        "from itertools import zip_longest\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "  \"Collect data into fixed-length chunks or blocks\"\n",
        "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
        "  args = [iter(iterable)] * n\n",
        "  return zip_longest(fillvalue = fillvalue, *args)\n",
        " "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbmH8xi5qdxm"
      },
      "source": [
        "def to1DArray_grayscale(img_bin_data):\n",
        "  pixel_array = []\n",
        "  \n",
        "  for x, y in grouper(img_bin_data, 2) :\n",
        "    \n",
        "    new_pixel = colormap[x][y]\n",
        "    \n",
        "    pixel_array.append(new_pixel)\n",
        "    \n",
        "  return pixel_array  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D23djA10hfK"
      },
      "source": [
        "#grayscale_array = to1DArray_grayscale(img_bin_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rFSLL3iMmLn"
      },
      "source": [
        "def to1DArray_RGB(img_bin_data):\n",
        "  pixel_array = []\n",
        "  for x, y in grouper(img_bin_data, 2) :\n",
        "    pixel_array.append((R_colormap[x][y], G_colormap[x][y], B_colormap[x][y]))\n",
        "    #print(pixel_array[index])\n",
        "  return pixel_array  "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SLS0eSpNkkr"
      },
      "source": [
        "#RGB_array = to1DArray_RGB(img_bin_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0mBG5y3z2Za"
      },
      "source": [
        "def saveImg (filename, data, size, img_type):\n",
        "  try:\n",
        "    image = Image.new(img_type, size)\n",
        "    #tuples = [tuple(x) for x in data]\n",
        "    #image.putdata(tuples)\n",
        "    image.putdata(data)\n",
        "    '''ref : https://stackoverflow.com/questions/68642888/issues-converting-rgb-to-image-with-correct-size'''\n",
        "    ''' ref: https://github.com/ncarkaci/binary-to-image\n",
        "    setup output filename\n",
        "    dirname     = os.path.dirname(filename)\n",
        "    name, _     = os.path.splitext(filename)\n",
        "    name        = os.path.basename(name)\n",
        "    imagename   = dirname + os.sep + img_type + os.sep + name + '_'+img_type+ '.png'\n",
        "    os.makedirs(os.path.dirname(imagename), exist_ok=True)'''\n",
        "    image.save(filename)\n",
        "    # print('The file', filename, 'saved.')\n",
        "  except Exception as err:\n",
        "    print(err)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3pgtozY028K"
      },
      "source": [
        "#saveImg('/content/output.png', grayscale_array, (512,512),'L')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crMaKBaHN8BG"
      },
      "source": [
        "#saveImg('/content/outputt.png', RGB_array, (512,512),'RGB')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX-EGgMGfLkG"
      },
      "source": [
        "def findMax(matrix):\n",
        "  max = 0\n",
        "  for i in range(0,256):\n",
        "    for j in range(0,256):\n",
        "      if matrix[i][j]>max:\n",
        "        max =  matrix[i][j]\n",
        "  return int(max)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cby38tHTz-L"
      },
      "source": [
        "def generateMarkovImg(binary_data):\n",
        "  # input B (binary_data) = {b1, b2, b3...bn} is a set where bi represents the deci\u0002mal value of a byte.\n",
        "  # TM[i][j] represents the probability that byte bi is fol\u0002lowed by bj\n",
        "  TM = np.zeros((256,256))\n",
        "  S = np.zeros((256,1))\n",
        "  L = len(binary_data)\n",
        "  #we determine the frequency of occur\u0002rence of byte bi followed by bi+1 and bi followed by bk where 0 ≤ k ≤ 255. \n",
        "  i=0\n",
        "  while i < L-1:\n",
        "    r = binary_data[i]\n",
        "    \n",
        "    c = binary_data[i+1]\n",
        "    \n",
        "    TM[r][c] = TM[r][c] +1\n",
        "    S[r] = S[r] + 1\n",
        "    \n",
        "    i = i+1\n",
        "\n",
        "  i = 0\n",
        "  j = 0\n",
        "  #compute the probability that byte bi is followed by bi+1\n",
        "  while i < 256:\n",
        "    rs = S[i]\n",
        "    while j < 256:\n",
        "      TM[i][j] = TM[i][j]/rs\n",
        "      j = j+1\n",
        "    i = i+1\n",
        "\n",
        "  print(\"TM shape\", TM.shape)\n",
        "  MP = findMax(TM)\n",
        "  print('max',MP)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  M =  np.zeros((256,256))\n",
        "  # compute pixels in Markov image\n",
        "  while i < 256:\n",
        "    while j < 256:\n",
        "      \n",
        "      p = (TM[i][j]*(255/MP))%256\n",
        "      M[i][j] = p\n",
        "      j = j+1\n",
        "    i = i+1\n",
        "  print(M)\n",
        "  return M\n",
        "  #Output: M = {m1, m2, m3...mn} is a set where mi represents a pixel value in Markov image.\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV-xhKyxYaoN"
      },
      "source": [
        "#saveImg('/content/outputtt.png', generateMarkovImg(img_bin_data), (512,512),'L')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PmKPDAsySOe"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "ksize = 3 # kernel size\n",
        "sigma = 3 # standard deviation\n",
        "theta = 180 # orientation of the Gabor function\n",
        "lambd = 180 # width of the strips of the Gabor function\n",
        "gamma = 0.5 # aspect ratio\n",
        "psi = 0 # phase offset\n",
        "ktype = ktype=cv2.CV_32F # \tType of filter coefficients. It can be CV_32F or CV_64F . ?? not specified in the paper\n",
        "\n",
        "# ref: https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gae84c92d248183bd92fa713ce51cc3599\n",
        "gabor_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
        "\n",
        "plt.imshow(gabor_kernel)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNjQ-57Y1fvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5121a157-6872-4a26-a450-056b8dca1d44"
      },
      "source": [
        "'''image = cv2.imread('/content/output.png') # reading image\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(image, cmap='gray') '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"image = cv2.imread('/content/output.png') # reading image\\n\\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\nplt.imshow(image, cmap='gray') \""
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qJCVWrR2tmp"
      },
      "source": [
        "filtered_image = cv2.filter2D(image, cv2.CV_8UC3, gabor_kernel)\n",
        "plt.imshow(filtered_image, cmap='gray') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EKKBUq49ZDe"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW-N4gguASLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46583ab3-495b-4ab3-fa19-345e60e14628"
      },
      "source": [
        "colormap = defineColorMap()\n",
        "R_colormap = defineColorMap()\n",
        "G_colormap = defineColorMap()\n",
        "B_colormap = defineColorMap()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[157 192 179 ... 194 127  91]\n",
            " [ 77  17  14 ...  62  47  90]\n",
            " [209  81 251 ... 152  50 220]\n",
            " ...\n",
            " [ 97 144 225 ... 128  52 129]\n",
            " [ 18 101  22 ...  62  57  93]\n",
            " [ 57  13  34 ... 208  31 113]]\n",
            "\n",
            "\n",
            "  (256, 256)\n",
            "[[170  45 102 ... 128 177  18]\n",
            " [145 232 170 ... 223 157 188]\n",
            " [216  43  92 ...   4 213 223]\n",
            " ...\n",
            " [ 56 218 203 ... 106  47  14]\n",
            " [248   1  78 ...  20 145  56]\n",
            " [207  77 177 ... 202 190  61]]\n",
            "\n",
            "\n",
            "  (256, 256)\n",
            "[[ 50 199  61 ... 252   3 185]\n",
            " [ 22  79  52 ... 154 212 146]\n",
            " [181 136 200 ...  84 193  42]\n",
            " ...\n",
            " [223 143 133 ...  94 150   6]\n",
            " [190   5  85 ... 133 183  68]\n",
            " [129 116  38 ... 222  58 202]]\n",
            "\n",
            "\n",
            "  (256, 256)\n",
            "[[ 45  13  17 ...  34  50 137]\n",
            " [164  57 196 ... 121 104 160]\n",
            " [195 120  41 ... 158 171 117]\n",
            " ...\n",
            " [ 69  94 125 ... 157  95  12]\n",
            " [151 236  47 ... 250 149  27]\n",
            " [195 211 233 ...   1  14 132]]\n",
            "\n",
            "\n",
            "  (256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvVjZt8Aqdm"
      },
      "source": [
        "from pathlib import Path\n",
        "Path(\"/content/dataset/Train\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/GRAY/m_greyscale\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/GRAY/b_greyscale\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/RGB/m_rgb\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/RGB/b_rgb\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/MARKOV/b_markov\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/Train/MARKOV/b_markov\").mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/data/dataset/training_set/cani/').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/data/dataset/training_set/gatti/').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/data/dataset/test_set/cani/').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/data/dataset/test_set/gatti/').mkdir(parents=True, exist_ok=True)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQqEVGAWNxQY"
      },
      "source": [
        "# save numpy array as npy file\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "\n",
        "save('/content/colormap.npy', colormap)\n",
        "save('/content/R_colormap.npy', R_colormap)\n",
        "save('/content/G_colormap.npy', G_colormap)\n",
        "save('/content/B_colormap.npy', B_colormap)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "rGhRincP910n",
        "outputId": "15700415-4d99-484b-96ca-5c3a54faadc5"
      },
      "source": [
        "dataset_dir = '/content/goodware/executables'\n",
        "dataset_dest_dir = '/content/dataset/Train'\n",
        "os.chdir(dataset_dir)\n",
        "for item in os.listdir(dataset_dir):\n",
        "  filename = dataset_dir + '/' + item\n",
        "  print(filename)\n",
        "  \n",
        "  img_bin_data = readBytes(item) \n",
        "  print(len(img_bin_data))\n",
        "  #img_bin_data = readBytes_fromNumpy('/content/123.npy')\n",
        "  \n",
        "  grayscale_array = to1DArray_grayscale(img_bin_data)\n",
        "  # print(grayscale_array)\n",
        "  dest = dataset_dest_dir+'/GRAY/b_greyscale/'+item[:-4]+\".jpg\"\n",
        "  saveImg(dest, grayscale_array, (width, height), 'L')\n",
        "  \n",
        "  ''' \n",
        "  RGB_array = to1DArray_RGB(img_bin_data)\n",
        "  dest = dataset_dest_dir+'/rgb/'+item[:-4]+\".jpg\"\n",
        "  saveImg(dest, RGB_array, (width, height), 'RGB')\n",
        "  dest = dataset_dest_dir+'/MARKOV/'+item[:-4]+\".jpg\"\n",
        "  saveImg('dest', generateMarkovImg(img_bin_data), (width, height), 'L')'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b04abbbc8939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/goodware/executables'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_dest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset/Train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/goodware/executables'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8IXAjkZajzK"
      },
      "source": [
        "# REPLACEMENT DS DA ELIMINARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpJo6797auRo",
        "outputId": "d9ed976d-e5b9-4725-a149-906dd99898a2"
      },
      "source": [
        "! kaggle datasets download -d chetankv/dogs-cats-images"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-cats-images.zip to /content\n",
            " 97% 422M/435M [00:03<00:00, 136MB/s]\n",
            "100% 435M/435M [00:03<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WEoES7-du6D"
      },
      "source": [
        "local_zip = '/content/dogs-cats-images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data')\n",
        "zip_ref.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBCzolF6Bqqk"
      },
      "source": [
        "! mv /content/data/dataset/training_set/dogs /content/data/dataset/training_set/cani\n",
        "! mv /content/data/dataset/training_set/cats /content/data/dataset/training_set/gatti"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEoTRmosB9au"
      },
      "source": [
        "! mv /content/data/dataset/test_set/dogs /content/data/dataset/test_set/cani\n",
        "! mv /content/data/dataset/test_set/cats /content/data/dataset/test_set/gatti"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHuPwrHIamti"
      },
      "source": [
        "# CONVERT DATA TO IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_qJIEevGB2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "79452ccd-884b-4db7-f9d9-d412ae53abc3"
      },
      "source": [
        "dataset_dir = '/content/bin_MalImg/train'\n",
        "dataset_dest_dir = '/content/dataset/Train'\n",
        "os.chdir(dataset_dir)\n",
        "for child_dir in os.listdir(dataset_dir):\n",
        "  current = dataset_dir+'/'+child_dir\n",
        "  os.chdir(current)\n",
        "  print(child_dir)\n",
        "  for item in os.listdir(current):\n",
        "    filename = dataset_dir + '/' + item\n",
        "    print(filename)\n",
        "    \n",
        "    #img_bin_data = readBytes(item) \n",
        "    img_bin_data = readBytes_fromNumpy(item)\n",
        "    print(len(img_bin_data))\n",
        "    \n",
        "    grayscale_array = to1DArray_grayscale(img_bin_data)\n",
        "    # print(grayscale_array)\n",
        "    # RGB_array = to1DArray_RGB(img_bin_data)\n",
        "    dest = dataset_dest_dir+\"/GRAY/m_greyscale/\"+item[:-4]+\".jpg\"\n",
        "    saveImg(dest, grayscale_array, (width, height), 'L')\n",
        "    \n",
        "   \n",
        "    ''' \n",
        "    RGB_array = to1DArray_RGB(img_bin_data)\n",
        "    dest = dataset_dest_dir+'/rgb/'+item[:-4]+\".jpg\"\n",
        "    saveImg(dest, RGB_array, (width, height), 'RGB')\n",
        "    dest = dataset_dest_dir+'/MARKOV/'+item[:-4]+\".jpg\"\n",
        "    saveImg('dest', generateMarkovImg(img_bin_data), (width, height), 'L')'''\n",
        "  os.chdir(dataset_dir)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4e7b92cf0732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/bin_MalImg/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_dest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset/Train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchild_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/bin_MalImg/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17aVSX40BGNB"
      },
      "source": [
        "dataset_dir = '/content/BIG2015'\n",
        "dataset_dest_dir = '/content/joinedMalImg'\n",
        "os.chdir(dataset_dir)\n",
        "for item in os.listdir(dataset_dir):\n",
        "  img_bin_data = readBytes(item)\n",
        "  #img_bin_data = readBytes_fromNumpy('/content/123.npy')\n",
        "  grayscale_array = to1DArray_grayscale(img_bin_data)\n",
        "  RGB_array = to1DArray_RGB(img_bin_data)\n",
        "  dest = dataset_dest_dir+\"/RGB/\"+item\n",
        "  saveImg(dest, grayscale_array, (width, height), 'L')\n",
        "  ''' dest = dataset_dest_dir+\"/Gray/\"+item\n",
        "  saveImg(dest, RGB_array, (width, height), 'RGB')\n",
        "  dest = dataset_dest_dir+\"/Markov/\"+item\n",
        "  saveImg('dest', generateMarkovImg(img_bin_data), (width, height), 'L')'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRoX96C-7Iuu"
      },
      "source": [
        "# Data Uploader class - UPDATED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgSYd85w6_vN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import os, os.path\n",
        "\n",
        "class UploadData():\n",
        "  def __init__(self):\n",
        "    #TRAINING_DIRECTORY = '/content/dataset/Train/GRAY'\n",
        "    #TRAINING_MAL_DIRECTORY = '/content/dataset/Train/GRAY/m_greyscale/'\n",
        "    #TRAINING_BEN_DIRECTORY = '/content/dataset/Train/GRAY/b_greyscale/'\n",
        "    \n",
        "    #TEST_MAL_DIRECTORY = '/content/dataset/Train/GRAY/m_greyscale/'\n",
        "    #TEST_BEN_DIRECTORY = '/content/dataset/Train/GRAY/b_greyscale/'\n",
        "    \n",
        "    self.TRAINING_MAL_DIRECTORY = '/content/data/dataset/training_set/gatti/'\n",
        "    self.TRAINING_BEN_DIRECTORY = '/content/data/dataset/training_set/cani/'\n",
        "    \n",
        "    self.TEST_MAL_DIRECTORY = '/content/data/dataset/test_set/gatti/'\n",
        "    self.TEST_BEN_DIRECTORY = '/content/data/dataset/test_set/cani/'\n",
        "    # path joining version for other paths\n",
        "    \n",
        "    self.mal_train_size = len([name for name in os.listdir(self.TRAINING_MAL_DIRECTORY+'cats') if os.path.isfile(os.path.join(self.TRAINING_MAL_DIRECTORY+'cats', name))])\n",
        "    self.ben_train_size = len([name for name in os.listdir(self.TRAINING_BEN_DIRECTORY+'dogs') if os.path.isfile(os.path.join(self.TRAINING_BEN_DIRECTORY+'dogs', name))])\n",
        "    self.mal_test_size = len([name for name in os.listdir(self.TEST_MAL_DIRECTORY+'cats') if os.path.isfile(os.path.join(self.TEST_MAL_DIRECTORY+'cats', name))])\n",
        "    self.ben_test_size = len([name for name in os.listdir(self.TEST_BEN_DIRECTORY+'dogs') if os.path.isfile(os.path.join(self.TEST_BEN_DIRECTORY+'dogs', name))])\n",
        "    \n",
        "    self.COLOR_MODE = 'grayscale'\n",
        "    self.IMAGE_HEIGHT = 256\n",
        "    self.IMAGE_WIDTH = 256\n",
        "    self.BATCH_SIZE = 32\n",
        "    self.VAL_SPLIT = 0.15\n",
        "    self.SEED = 1337\n",
        "    self.trian_mal_lbls = [1] * self.mal_train_size\n",
        "    self.trian_ben_lbls = [0] * self.ben_train_size\n",
        "    self.test_mal_lbls = [1] * self.mal_test_size\n",
        "    self.test_ben_lbls = [0] * self.ben_test_size\n",
        "\n",
        "\n",
        "  '''def __init__(self):\n",
        "  training_mal_set,vali_mal_set = self.upload_mal_set()\n",
        "  training_ben_set,vali_ben_set = self.upload_ben_set()\n",
        "  training_set,vali_set = self.upload_set()'''\n",
        "\n",
        "  def upload_train_mal_set(self):\n",
        "    training_mal_set = keras.preprocessing.image_dataset_from_directory(\n",
        "            self.TRAINING_MAL_DIRECTORY,\n",
        "            labels = self.trian_mal_lbls ,\n",
        "            label_mode = 'int',\n",
        "            color_mode=self.COLOR_MODE,\n",
        "            validation_split=self.VAL_SPLIT,\n",
        "            subset='training',\n",
        "            seed=self.SEED,\n",
        "            interpolation=\"area\",\n",
        "            batch_size=self.BATCH_SIZE,\n",
        "            image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "            shuffle=True\n",
        "    )\n",
        "\n",
        "    val_mal_set = keras.preprocessing.image_dataset_from_directory(\n",
        "      self.TRAINING_MAL_DIRECTORY,\n",
        "      labels = self.trian_mal_lbls ,\n",
        "      label_mode = 'int', \n",
        "      color_mode=self.COLOR_MODE,\n",
        "      subset='validation',\n",
        "      validation_split=self.VAL_SPLIT,\n",
        "      seed=self.SEED,\n",
        "      interpolation=\"area\",\n",
        "      batch_size=self.BATCH_SIZE,\n",
        "      image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "      shuffle=True\n",
        "    )\n",
        "    return training_mal_set, val_mal_set\n",
        "\n",
        "  def upload_train_ben_set(self):\n",
        "    training_ben_set = keras.preprocessing.image_dataset_from_directory(\n",
        "      self.TRAINING_BEN_DIRECTORY,            \n",
        "      labels = self.trian_ben_lbls,\n",
        "      label_mode = 'int',\n",
        "      color_mode=self.COLOR_MODE,\n",
        "      validation_split=self.VAL_SPLIT,\n",
        "      subset='training',\n",
        "      seed=self.SEED,\n",
        "      interpolation=\"area\",\n",
        "      batch_size=self.BATCH_SIZE,\n",
        "      image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "      shuffle=True,\n",
        "    )\n",
        "    val_ben_set = keras.preprocessing.image_dataset_from_directory(\n",
        "      self.TRAINING_BEN_DIRECTORY,\n",
        "      labels= self.trian_ben_lbls,\n",
        "      label_mode=\"int\",\n",
        "      color_mode=self.COLOR_MODE,\n",
        "      validation_split=self.VAL_SPLIT,\n",
        "      subset='validation',\n",
        "      seed=self.SEED,\n",
        "      interpolation=\"area\",\n",
        "      batch_size=self.BATCH_SIZE,\n",
        "      image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "      shuffle=True\n",
        "    )\n",
        "    return training_ben_set, val_ben_set\n",
        "\n",
        "  def upload_training_set(self, training_ben_set, vali_ben_set, training_mal_set, val_mal_set):\n",
        "    training_set = training_ben_set.concatenate(training_mal_set)\n",
        "    training_set = training_set.unbatch()\n",
        "    training_set = training_set.shuffle(int((1-self.VAL_SPLIT)*(float(self.ben_train_size+self.mal_train_size))))\n",
        "    training_set = training_set.batch(self.BATCH_SIZE)\n",
        "\n",
        "    val_set = vali_ben_set.concatenate(val_mal_set)\n",
        "    val_set = val_set.unbatch()\n",
        "    val_set = val_set.shuffle(int((self.VAL_SPLIT)*(float(self.ben_train_size+self.mal_train_size))))\n",
        "    val_set = val_set.batch(self.BATCH_SIZE)\n",
        "    return training_set, val_set\n",
        "\n",
        "\n",
        "\n",
        "  def upload_test_mal_set(self):\n",
        "    test_mal_set = keras.preprocessing.image_dataset_from_directory(\n",
        "            self.TEST_MAL_DIRECTORY,\n",
        "            labels = self.test_mal_lbls ,\n",
        "            label_mode = 'int',\n",
        "            color_mode=self.COLOR_MODE,\n",
        "            seed=self.SEED,\n",
        "            interpolation=\"area\",\n",
        "            batch_size=self.BATCH_SIZE,\n",
        "            image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "            shuffle=True\n",
        "    )\n",
        "    return test_mal_set\n",
        "\n",
        "  def upload_test_ben_set(self):\n",
        "    test_ben_set = keras.preprocessing.image_dataset_from_directory(\n",
        "            self.TEST_BEN_DIRECTORY,\n",
        "            labels = self.test_ben_lbls ,\n",
        "            label_mode = 'int',\n",
        "            color_mode=self.COLOR_MODE,\n",
        "            seed=self.SEED,\n",
        "            interpolation=\"area\",\n",
        "            batch_size=self.BATCH_SIZE,\n",
        "            image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "            shuffle=True\n",
        "    )\n",
        "    return test_ben_set\n",
        "\n",
        "  def upload_test_set(self, test_ben_set, test_mal_set):\n",
        "    test_set = test_ben_set.concatenate(test_mal_set)\n",
        "    test_set = test_set.unbatch()\n",
        "    test_set = test_set.shuffle(int((1-self.VAL_SPLIT)*(float(self.ben_test_size+self.mal_test_size))))\n",
        "    test_set = test_set.batch(self.BATCH_SIZE)\n",
        "    return test_set\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # how to get the dataset:    \n",
        "    # https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb?hl=zh-tw#scrollTo=ucMoYase6URl\n",
        "  def shuffle_nomalize(self, mixdata_set, mal_set, ben_set):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    mixdata_ds = mixdata_set.cache().shuffle(11929).prefetch(buffer_size=AUTOTUNE)\n",
        "    mal_ds = mal_set.cache().shuffle(11929).prefetch(buffer_size=AUTOTUNE)\n",
        "    ben_ds = ben_set.cache().shuffle(11929).prefetch(buffer_size=AUTOTUNE)\n",
        "    # test_ds = test_set.cache().shuffle(11929).prefetch(buffer_size=AUTOTUNE)\n",
        "    # validation_ds = validation_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # The RGB channel values are in the [0, 255] range. This is not ideal for a neural network;\n",
        "    #  in general you should seek to make your input values small.\n",
        "    #  Here, you will standardize values to be in the [0, 1] range by using the tf.keras.layers.experimental.preprocessing.Rescaling layer.\n",
        "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "\n",
        "    normalized_ds = mixdata_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    normalized_mal_ds = mal_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    normalized_ben_ds = ben_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    # normalized_test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    # normalized_validatioin_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    return normalized_ds, normalized_mal_ds, normalized_ben_ds\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setAhfXOZ5Fy",
        "outputId": "e7be3d10-1b3a-4472-8a8d-35c37b76d5f6"
      },
      "source": [
        "uploader = UploadData()\n",
        "cats_train, cats_val = uploader.upload_train_mal_set()\n",
        "cats_test =uploader.upload_test_mal_set()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 1 classes.\n",
            "Using 3400 files for training.\n",
            "Found 4000 files belonging to 1 classes.\n",
            "Using 600 files for validation.\n",
            "Found 1000 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swkMtAkJbbG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5594668d-7a0b-478a-deeb-86af0fbee7bb"
      },
      "source": [
        "dogs_train, dogs_val = uploader.upload_train_ben_set()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 1 classes.\n",
            "Using 3400 files for training.\n",
            "Found 4000 files belonging to 1 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coGbl7DnYomg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946480cf-8fa4-4c4d-cf96-d1f6cbdb1cc8"
      },
      "source": [
        "for img_batch_cat,img_batch_dog in zip(cats_train,dogs_train):\n",
        " #print(\"mal_batch\")\n",
        " #print(img_batch_cat)\n",
        " print(\"ben_batch\")\n",
        " #print(img_batch_dog)\n",
        " break\n",
        " #images,label = img_batch_mal"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ben_batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2d1Ec0rbbzX"
      },
      "source": [
        "mixed_train, mixed_val = uploader.upload_training_set(dogs_train, dogs_val,cats_train, cats_val)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "211ankz6d_lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ce3ca8-da5e-4cdc-c481-1b14d869f695"
      },
      "source": [
        "from matplotlib.pyplot import figure, imshow, axis\n",
        "irra=0\n",
        "\n",
        "for c_batch in mixed_train:\n",
        "  imgsa, lblsa = c_batch \n",
        "  print(len(lblsa))\n",
        "  # for i in range(0,20):\n",
        "  #   figure_1a = figure(figsize=(30, 30), dpi=100)\n",
        "  #   subplota=figure_1a.add_subplot(16,16,3)\n",
        "  #   #print(lblsa[i])\n",
        "  #   imshow(imgsa[i].numpy().astype(\"uint8\").squeeze())\n",
        "  # #irra = irra+1\n",
        "  # #print(irra)\n",
        "  break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oh5FIED7BTo"
      },
      "source": [
        "# Blackbox detector "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaqoQSY-61zN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf;\n",
        "from tensorflow import keras;\n",
        "from tensorflow.keras import layers, models, applications, optimizers, losses, metrics\n",
        "from keras.callbacks import *\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MalwareDetectionModels:\n",
        "    TRAINING_DATA_DIRECTORY = '/content/data/dataset/training_set'\n",
        "    TEST_DATA_DIRECTORY = '/content/data/dataset/test_set'\n",
        "    COLOR_MODE = 'grayscale'\n",
        "    IMAGE_HEIGHT = 256\n",
        "    IMAGE_WIDTH = 256\n",
        "    BATCH_SIZE = 10\n",
        "    SEED = 1337\n",
        "\n",
        "    SEED = 1337\n",
        "\n",
        "    def __init__(self, img_w, img_h, model_name,training_set, validation_set):\n",
        "        self.image_width = img_w\n",
        "        self.image_height = img_h\n",
        "        self.model = None\n",
        "        if model_name == \"M1\":\n",
        "            self.model = self.bulid_m1()\n",
        "            self.epochs = 50\n",
        "            self.rate = 0.000075\n",
        "        elif model_name == \"M2\":\n",
        "            self.model = self.bulid_m2()\n",
        "            self.epochs = 50\n",
        "            self.rate = 0.00001\n",
        "        elif model_name == \"M3\":\n",
        "            '''  In M-3, initially, each input image has to go through three convolution layers of 32 neurons each.\n",
        "             Then it has to go through a max pooling layer and finally through a fully connected layer of 16384 neurons. \n",
        "             It executed for 200 epochs, with a batch size of 32, and a learning rate of 0.0001.'''\n",
        "            self.model = self.bulid_m3()\n",
        "            self.epochs = 200\n",
        "            self.batch_size = 32\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M4\":\n",
        "            self.model = self.bulid_m4()\n",
        "            self.epochs = 120\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M5\":\n",
        "            # M-5 (convolution followed by global pool and a fully connected layer) has again poor per\u0002formances. T\n",
        "            self.model = self.bulid_m5()\n",
        "            self.epochs = 50\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M6\":\n",
        "            self.model = self.bulid_m6()\n",
        "            self.epochs = 50\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M7\":\n",
        "            self.model = self.bulid_m7()\n",
        "            self.epochs = 250\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M8\":\n",
        "            self.model = self.bulid_m8()\n",
        "            self.epochs = 200\n",
        "            self.rate = 0.01\n",
        "        elif model_name == \"M9\":\n",
        "            self.model = self.bulid_m9()\n",
        "            self.epochs = 30\n",
        "            self.rate = 0.0001\n",
        "        elif model_name == \"M10\":\n",
        "            '''  Here, in the case of M-10 (VGG3 with dropout) the network topology is VGG3 \n",
        "            followed by three fully connected layers with 1024, 2048 and 4096 respec\u0002tively. \n",
        "            Hyperparameters are leraning rate of 0.0001 and batch size of 64.'''\n",
        "            self.model = self.bulid_m10()\n",
        "            self.epochs = 30\n",
        "            self.rate = 0.0001\n",
        "        elif model_name == \"M11\":\n",
        "            '''\n",
        "            Filter size of convolution layer used is 3×3 for all the models.\n",
        "      \n",
        "            Its architecture is com\u0002posed of VGG3 followed by three fully connected layers of 4096 neurons each.\n",
        "             In this model dropout rates of 0.2, 0.2, 0.3, and batch normalization were included between \n",
        "             the convolution\u0002pooling layers of VGG3. In addition, same dropout rates and batch normalization \n",
        "             were added in between fully connected layers.\n",
        "      \n",
        "            for M-11 (VGG3 with dropout and batch nor\u0002malization) were 30 epochs, batch-size of 64 and a learning\n",
        "            rate of 0.0001 on Dataset-I while the number of epochs were increased to 200 for M-11 (VGG3 with dropout and batch nor\u0002malization) on Dataset-II\n",
        "            '''\n",
        "            '''model M-11 (VGG3 with dropout and batch normalization) reports high performance \n",
        "            measures with a rise of 0.89% and 1.83% in F-measure compared to the model M-11 \n",
        "            (VGG3 with dropout and batch normalization) generated us\u0002ing RGB images of Dataset-I \n",
        "            and Dataset-II respectively. The model M-11 (VGG3 with dropout and batch normalization) \n",
        "            was executed for 50 epochs with dropout rates 0.1, 0.2, 0.3 and learning rate 0.0001 on Dataset-I. For Dataset-II the dropouts were 0.1, 0.2, 0.3 with a learning rate of 0.000007. However, the epochs remained the same.'''\n",
        "            self.batch_size = 64\n",
        "            self.model = self.bulid_m11()\n",
        "            self.epochs = 5\n",
        "            self.rate = 0.0001\n",
        "        elif model_name == \"M12\":\n",
        "            ''' ResNet-50 along with three fully connected layers of 1024, 512 and 256 neurons.'''\n",
        "            self.model = self.bulid_m12()\n",
        "            self.epochs = 30\n",
        "            self.rate = 0.0001\n",
        "\n",
        "        self.define_callbacks()\n",
        "        self.history = self.train_bb_detector(training_set, validation_set)\n",
        "        # self.evaluate_bb_detector()\n",
        "        # self.plot_history()\n",
        "\n",
        "    def bulid_m1(self):\n",
        "        m1 = models.Sequential()\n",
        "        # m1.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Conv + Pool + Dense +Dense\n",
        "        m1.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 1)))\n",
        "        m1.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m1.add(layers.MaxPooling2D(pool_size=2))\n",
        "        m1.add(layers.Flatten())  # if it is not flattened, only the last layer can be fed into the dense\n",
        "        m1.add(layers.Dense(1024, activation='relu'))\n",
        "        m1.add(layers.Dense(2, activation='relu'))\n",
        "        return m1\n",
        "\n",
        "    def bulid_m2(self):\n",
        "        m2 = models.Sequential()\n",
        "        # m2.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Pool + Dense + Dense\n",
        "        m2.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 1)))\n",
        "        m2.add(layers.MaxPooling2D(pool_size=2))\n",
        "        # m2.add(layers.Flatten())#if it is not flattened, only the last layer can be fed into the dense\n",
        "        m2.add(layers.Dense(128, activation='relu'))\n",
        "        m2.add(layers.Dense(128, activation='relu'))\n",
        "        return m2\n",
        "\n",
        "    def bulid_m3(self):\n",
        "        m3 = models.Sequential()\n",
        "        # m3.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3))) \n",
        "        # Conv + Conv + Conv + Pool + Dense + Dense\n",
        "        m3.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 1)))\n",
        "        m3.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m3.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m3.add(layers.MaxPooling2D(pool_size=2))\n",
        "        # m3.add(layers.Flatten())#if it is not flattened, only the last layer can be fed into the dense\n",
        "        m3.add(layers.Dense(128, activation='relu'))\n",
        "        m3.add(layers.Dense(128, activation='relu'))\n",
        "        return m3\n",
        "\n",
        "    def bulid_m4(self):\n",
        "        m4 = models.Sequential()\n",
        "        # m4.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # onv + Pool + Conv + Dense + Dense\n",
        "        m4.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m4.add(layers.MaxPooling2D(pool_size=2))\n",
        "        m4.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        # m4.add(layers.Flatten())#if it is not flattened, only the last layer can be fed into the dense\n",
        "        m4.add(layers.Dense(128, activation='relu'))\n",
        "        m4.add(layers.Dense(128, activation='relu'))\n",
        "        return m4\n",
        "\n",
        "    def bulid_m5(self):\n",
        "        m5 = models.Sequential()\n",
        "        # m5.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Globalpool + Dense + Dense\n",
        "        m5.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m5.add(layers.GlobalMaxPooling2D(data_format=None, keepdims=False))\n",
        "        # m5.add(layers.Flatten())#if it is not flattened, only the last layer can be fed into the dense\n",
        "        m5.add(layers.Dense(128, activation='relu'))\n",
        "        m5.add(layers.Dense(128, activation='relu'))\n",
        "        return m5\n",
        "\n",
        "    def bulid_m6(self):\n",
        "        m6 = models.Sequential()\n",
        "        # m6.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Conv + Globalpool + Dense + Dense   \n",
        "        m6.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m6.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m6.add(layers.GlobalMaxPooling2D(data_format=None, keepdims=False))\n",
        "        # m6.add(layers.Flatten())#if it is not flattened, only the last layer can be fed into the dense\n",
        "        m6.add(layers.Dense(128, activation='relu'))\n",
        "        m6.add(layers.Dense(128, activation='sigmoid'))\n",
        "        return m6\n",
        "\n",
        "    def bulid_m7(self):\n",
        "        m7 = models.Sequential()\n",
        "        # m7.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Pool + Conv + Pool + Dense + Dens\n",
        "        m7.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m7.add(layers.MaxPooling2D())\n",
        "        m7.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m7.add(layers.MaxPooling2D())\n",
        "        m7.add(layers.Dense(128, activation='relu'))\n",
        "        m7.add(layers.Dense(128, activation='sigmoid'))\n",
        "        return m7\n",
        "\n",
        "    def bulid_m8(self):\n",
        "        m8 = models.Sequential()\n",
        "        # m8.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        # Conv + Pool + Conv + Pool + Conv + Pool + Dense + Dense\n",
        "        m8.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m8.add(layers.MaxPooling2D())\n",
        "        m8.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m8.add(layers.MaxPooling2D())\n",
        "        m8.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m8.add(layers.MaxPooling2D())\n",
        "        m8.add(layers.Dense(128, activation='relu'))\n",
        "        m8.add(layers.Dense(128, activation='sigmoid'))\n",
        "        return m8\n",
        "\n",
        "    def bulid_m9(self):\n",
        "        m9 = models.Sequential()\n",
        "        # m9.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                             input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m9.add(layers.MaxPooling2D())\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m9.add(layers.MaxPooling2D())\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m9.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m9.add(layers.MaxPooling2D())\n",
        "        m9.add(layers.Dense(128, activation='relu'))\n",
        "        m9.add(layers.Dense(128, activation='relu'))\n",
        "        m9.add(layers.Dense(128, activation='relu'))\n",
        "        m9.add(layers.Dense(128, activation='sigmoid'))\n",
        "        return m9\n",
        "\n",
        "    def bulid_m10(self):\n",
        "        m10 = models.Sequential()\n",
        "        # m10.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                              input_shape=(256,256,1)))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m10.add(layers.MaxPooling2D())\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m10.add(layers.MaxPooling2D())\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m10.add(layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "        m10.add(layers.MaxPooling2D())\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Dense(128, activation='relu'))\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Dense(128, activation='relu'))\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Dense(128, activation='relu'))\n",
        "        m10.add(layers.Dropout(.2))\n",
        "        m10.add(layers.Dense(128, activation='sigmoid'))\n",
        "        return m10\n",
        "\n",
        "    def bulid_m11(self):\n",
        "        ''' the dropout rates of 0.2, 0.3, 0.4 and batch normalization assigned between the convolution-pooling layers of VGG3, also the same added be\u0002tween the three fully connected layers of 4096 neurons each '''\n",
        "        m11 = models.Sequential()\n",
        "        #m11.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 1)))\n",
        "\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu',input_shape=(self.image_width, self.image_height, 1)))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.MaxPooling2D())\n",
        "        m11.add(layers.Dropout(.2))\n",
        "\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.MaxPooling2D())\n",
        "        m11.add(layers.Dropout(.3, input_shape=(2,)))\n",
        "\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.MaxPooling2D())\n",
        "        m11.add(layers.Dropout(.4, input_shape=(2,)))\n",
        "\n",
        "        m11.add(layers.Flatten())\n",
        "        m11.add(layers.Dense(4096, activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Dropout(.2))\n",
        "        m11.add(layers.Dense(4096, activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Dropout(.3, input_shape=(2,)))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Dense(4096, activation='relu'))\n",
        "        m11.add(layers.BatchNormalization())\n",
        "        m11.add(layers.Dropout(.4, input_shape=(2,)))\n",
        "        m11.add(layers.Dense(2, activation='sigmoid'))\n",
        "        return m11\n",
        "\n",
        "    def bulid_m12(self):\n",
        "        m12 = models.Sequential([\n",
        "            # layers.experimental.preprocessing.Rescaling(1./255, input_shape=(self.image_width, self.image_height, 3)),\n",
        "            applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
        "                                           pooling=None, classes=1000),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(1024, activation='relu'),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(256, activation='sigmoid'),\n",
        "        ])\n",
        "        return m12\n",
        "\n",
        "    def define_callbacks(self):\n",
        "        checkpoint_cb = ModelCheckpoint(\"/content/Model.h5\", save_freq=\"epoch\", save_best_only=True)\n",
        "        early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "        logger_cb = CSVLogger('training.log', separator=\"|\")\n",
        "        return [checkpoint_cb, early_stopping_cb, logger_cb]\n",
        "\n",
        "    def train_bb_detector(self,training_set,validation_set):\n",
        "      \n",
        "        #uploader = UploadData()\n",
        "        #training_set, validation_set = uploader.upload_set()\n",
        "        # binary crossentropy or sparse categorical???\n",
        "      self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "      history = self.model.fit(training_set, epochs=self.epochs, validation_data=validation_set,\n",
        "                                 callbacks=self.define_callbacks())\n",
        "      return history\n",
        "\n",
        "    def plot_history(self):\n",
        "      data_frame = pandas.DataFrame(self.history.history)\n",
        "      data_frame.plot(figsize=(7, 3))\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Sparse categorical cross-entropy')\n",
        "\n",
        "    def evaluate_bb_detector(self):\n",
        "      #uploader = UploadData()\n",
        "      #test_set = uploader.upload_test_set('/content/dataseett/dataset/test_set')\n",
        "      validation_set = keras.preprocessing.image_dataset_from_directory(\n",
        "          self.TEST_DATA_DIRECTORY,\n",
        "          labels='inferred', \n",
        "          label_mode='int',\n",
        "          class_names=None,\n",
        "          color_mode=self.COLOR_MODE,\n",
        "          seed=self.SEED,\n",
        "          interpolation=\"area\",\n",
        "          batch_size=self.BATCH_SIZE,\n",
        "          image_size=(self.IMAGE_HEIGHT, self.IMAGE_WIDTH),\n",
        "          shuffle=True,\n",
        "      )\n",
        "      test_loss, test_acc = self.model.evaluate(test_set, verbose=2)\n",
        "      print('\\nTest accuracy:', test_acc)\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFM0D2ytsAHh",
        "outputId": "42fbd967-4999-4283-82e0-5748e2b974cd"
      },
      "source": [
        "dogs_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 256, 256, 1), (None,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEZYKF3bexI_",
        "outputId": "e6236048-3927-40c1-c9eb-813e82454a50"
      },
      "source": [
        "mixed_train\n",
        "          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 256, 256, 1), (None,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mizbjLyQuwlC",
        "outputId": "94b99c05-6f0d-4807-80d1-07105251101d"
      },
      "source": [
        "mixed_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 256, 256, 1), (None,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wplXi6o_en8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf31b45-98dd-4c9e-8a8c-f6aa7cd0c885"
      },
      "source": [
        "bb_detector = MalwareDetectionModels(width, height, 'M11',mixed_train, mixed_val)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "213/213 [==============================] - 120s 377ms/step - loss: 1.3629 - accuracy: 0.5671 - val_loss: 0.7998 - val_accuracy: 0.6017\n",
            "Epoch 2/5\n",
            "213/213 [==============================] - 89s 374ms/step - loss: 0.8182 - accuracy: 0.6240 - val_loss: 1.0868 - val_accuracy: 0.6058\n",
            "Epoch 3/5\n",
            "213/213 [==============================] - 89s 373ms/step - loss: 0.7593 - accuracy: 0.6596 - val_loss: 1.3442 - val_accuracy: 0.6150\n",
            "Epoch 4/5\n",
            "213/213 [==============================] - 88s 372ms/step - loss: 0.6548 - accuracy: 0.7190 - val_loss: 0.8081 - val_accuracy: 0.6258\n",
            "Epoch 5/5\n",
            "213/213 [==============================] - 89s 373ms/step - loss: 0.5784 - accuracy: 0.7554 - val_loss: 0.6911 - val_accuracy: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdYjLZ1A7QWt"
      },
      "source": [
        "# Master Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdvShTEM7VHV"
      },
      "source": [
        "# from Models import MalwareDetectionModels\n",
        "# from UploadData import UploadData\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers, models, applications, optimizers, losses, metrics\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras import layers\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from IPython import display\n",
        "\n",
        "class MasterGAN:\n",
        "    BUFFER_SIZE = 60000\n",
        "    BATCH_SIZE = 256\n",
        "\n",
        "    def __init__(self, blackbox, img_w=256, img_h=256):\n",
        "        # initialize image aspect ratio\n",
        "        self.img_width = img_w\n",
        "        self.img_height = img_h\n",
        "        self.EPOCHS = 50\n",
        "        self.noise_dim = 256\n",
        "        \n",
        "        self.num_examples_to_generate = 16\n",
        "\n",
        "        # You will reuse this seed overtime (so it's easier)\n",
        "        # to visualize progress in the animated GIF)\n",
        "        self.seed = tf.random.normal([self.num_examples_to_generate, self.noise_dim])\n",
        "        \n",
        "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "        ''' add this option???\n",
        "        self.same_train_data = same_train_data   # MalGAN and the black-boxdetector are trained on same or different training sets\n",
        "        '''\n",
        "\n",
        "        \n",
        "\n",
        "        # load model file, the blackbox detector is trained upon calling the init function.\n",
        "        # In any case, it is trained externally\n",
        "        self.blackbox = blackbox\n",
        "        #self.blackbox_detector = bb_detector\n",
        "        #self.blackbox_detector = MalwareDetectionModels(self.img_width, self.img_height, self.blackbox)\n",
        "        #self.bb_detector = MalwareDetectionModels(img_width, img_height, blackbox)\n",
        "\n",
        "\n",
        "        ####### define GAN #########\n",
        "        self.substitute_detector_optimizer = tf.keras.optimizers.Adam(lr=1e-5, beta_1=0.1)\n",
        "        self.generator_optimizer = tf.keras.optimizers.Adam(lr=2e-4, beta_1=0.5)\n",
        "        self.generator = self.build_generative_model()\n",
        "        self.substitute_detector = self.build_substitute_detector_model()\n",
        "\n",
        "        '''###load the dataset####\n",
        "        uploader = UploadData()\n",
        "        self.train_mal_set, self.val_mal_set = uploader.upload_train_mal_set()\n",
        "        self.train_ben_set, self.val_ben_set = uploader.upload_train_ben_set()\n",
        "        self.test_mal_set = uploader.upload_test_mal_set()\n",
        "        self.test_ben_set = uploader.upload_test_ben_set()'''\n",
        "\n",
        "\n",
        "   \n",
        "    def build_generative_model(self):\n",
        "        #ref https://www.tensorflow.org/tutorials/generative/pix2pix\n",
        "        # generator = models.Sequential() # Sequential model is not appropriate when: Your model has multiple inputs\n",
        "        # or multiple outputs ref: https://keras.io/guides/sequential_model/\n",
        "        noise_input = Input(shape=(256,self.noise_dim)) #if we want the noise with size 256*256,we can use shape=(noise_dim,self.noise_dim)\n",
        "        mal_sample_input = Input(shape=(self.img_width,self.img_height))\n",
        "        final_input = Concatenate(axis = 1)([mal_sample_input, noise_input])\n",
        "        print(final_input)\n",
        "        current_output = layers.Dense(32, use_bias=False)(final_input)\n",
        "        current_output = layers.BatchNormalization()(current_output)\n",
        "        current_output = layers.LeakyReLU()(current_output)\n",
        "\n",
        "        current_output = layers.Reshape((32, 32, 16))(current_output)\n",
        "        # assert current_output.output_shape == (None, 32, 32, 16)  # Note: None is the batch size\n",
        "\n",
        "        current_output = layers.Conv2DTranspose(8, (5, 5), strides=(2, 2), padding='same', use_bias=False)(\n",
        "            current_output)\n",
        "        # assert current_output.output_shape == (None, 64, 64, 8)(current_output)\n",
        "        current_output = layers.BatchNormalization()(current_output)\n",
        "        current_output = layers.LeakyReLU()(current_output)\n",
        "\n",
        "        current_output = layers.Conv2DTranspose(4, (5, 5), strides=(2, 2), padding='same', use_bias=False)(\n",
        "            current_output)\n",
        "        # assert current_output.output_shape == (None, 128, 128, 4)\n",
        "        current_output = layers.BatchNormalization()(current_output)\n",
        "        current_output = layers.LeakyReLU()(current_output)\n",
        "\n",
        "        current_output = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False,\n",
        "                                                activation='tanh')(current_output)\n",
        "        # assert current_output.output_shape == (None, 256, 256, 1)\n",
        "        generator = Model(inputs=[noise_input, mal_sample_input], outputs=[current_output])\n",
        "        #print(generator.summary())\n",
        "        tf.keras.utils.plot_model(\n",
        "            generator,to_file='/content/data/model.png', show_shapes=True, show_dtype=True,\n",
        "            show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n",
        "            layer_range=None)\n",
        "        return generator\n",
        "\n",
        "    def build_substitute_detector_model(self):\n",
        "\n",
        "        # it can be a convolutional network which works as a classifier\n",
        "        substitute_detector = tf.keras.Sequential()\n",
        "        substitute_detector.add(layers.Conv2D(64, (5, 5), activation='relu', strides=(2, 2), padding='same',\n",
        "                                              input_shape=[self.img_width, self.img_height, 1]))\n",
        "\n",
        "        substitute_detector.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "        substitute_detector.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "        substitute_detector.add(layers.Conv2D(128, (5, 5), strides=(5, 5), padding='same'))\n",
        "        substitute_detector.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "        substitute_detector.add(layers.Flatten())\n",
        "        substitute_detector.add(layers.Dense(64, activation='relu'))\n",
        "        substitute_detector.add(layers.Dropout(0.4))\n",
        "        substitute_detector.add(layers.Dense(32, activation='relu'))\n",
        "        substitute_detector.add(layers.Dropout(0.3))\n",
        "\n",
        "        substitute_detector.add(layers.Dense(2, activation='sigmoid'))\n",
        "        return substitute_detector\n",
        "\n",
        "    \n",
        "    def substitute_detector_loss(self, sd_on_real, sd_on_adv, bb_on_real, bb_on_adv):\n",
        "        # the loss for the discriminator is computed as the sum of the loss related to real samples not being\n",
        "        # classified correctly and the loss related to generated samples not being classified correctly\n",
        "        real_loss = self.cross_entropy(bb_on_real, sd_on_real)\n",
        "        fake_loss = self.cross_entropy(bb_on_adv, sd_on_adv)\n",
        "        total_loss = real_loss + fake_loss\n",
        "        return total_loss\n",
        "\n",
        "    def generator_loss(self, sd_on_adv):\n",
        "        return self.cross_entropy(tf.ones_like(sd_on_adv), sd_on_adv)\n",
        "\n",
        "    def checkpoint(self):\n",
        "      checkpoint_dir = '/content/sample_data/'\n",
        "      checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "      checkpoint = tf.train.Checkpoint(generator_optimizer=self.generator_optimizer,\n",
        "                                      substitute_detector_optimizer=self.substitute_detector_optimizer,\n",
        "                                      generator=self.generator,\n",
        "                                      discriminator=self.substitute_detector)\n",
        "      return checkpoint,checkpoint_prefix\n",
        "    # Notice the use of `tf.function`\n",
        "    # This annotation causes the function to be \"compiled\".\n",
        "    @tf.function\n",
        "    def train_step(self,batch_mal, batch_ben):\n",
        "        # in redefining how the function .fit() behaves for a model, the train_step(self,data) function needs to be\n",
        "        # overridden ref https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "        img_batch_mal, lbls_mal = batch_mal\n",
        "        img_batch_ben, lbls_ben = batch_ben\n",
        "        img_nums= len(lbls_mal)\n",
        "        new_noise = tf.random.normal([img_nums,self.img_width, self.img_height])\n",
        "   \n",
        "\n",
        "        ''' \"TensorFlow provides the tf.GradientTape API for automatic differentiation; \n",
        "                that is, computing the gradient of a computation with respect to some inputs, \n",
        "                usually tf.Variables. TensorFlow \"records\" relevant operations executed inside \n",
        "                the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape \n",
        "                to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\"'''\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # with each step the generator produces a set of images\n",
        "            \n",
        "            adv_malware_samples = self.generator([new_noise,img_batch_mal], training=True)\n",
        "\n",
        "            # the discriminator makes predictions on real images first, then on adversarial samples. Each prediction\n",
        "            # is stored into a variable and used to evaluate the discriminator loss\n",
        "            bb_on_real = self.blackbox.model(img_batch_ben)\n",
        "            sd_on_real = self.substitute_detector(img_batch_ben, training=True)\n",
        "            bb_on_adv = self.blackbox.model(adv_malware_samples)\n",
        "            sd_on_adv = self.substitute_detector(adv_malware_samples, training=True)\n",
        "\n",
        "            gen_loss = self.generator_loss(sd_on_adv)\n",
        "            disc_loss = self.substitute_detector_loss(sd_on_real, sd_on_adv, bb_on_real, bb_on_adv)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        gradients_of_sub_detector = disc_tape.gradient(disc_loss, self.substitute_detector.trainable_variables)\n",
        "\n",
        "        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.substitute_detector_optimizer.apply_gradients(\n",
        "            zip(gradients_of_sub_detector, self.substitute_detector.trainable_variables))\n",
        "    \n",
        "    def train(self,ben_images, mal_images,test_mal_set):\n",
        "      ckpt,ckpt_prefix = self.checkpoint()\n",
        "      for epoch in range(self.EPOCHS):\n",
        "        start = time.time()\n",
        "        for batch_mal,batch_ben in zip(mal_images,ben_images):\n",
        "\n",
        "          self.train_step(batch_mal,batch_ben)\n",
        "        '''\n",
        "        # Produce images for the GIF as you go\n",
        "        display.clear_output(wait=True)\n",
        "        self.generate_and_save_images(self.generator,epoch + 1,test_mal_set,self.seed)\n",
        "                                \n",
        "\n",
        "        # Save the model every 15 epochs\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "          ckpt.save(file_prefix = ckpt_prefix)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "      # Generate after the final epoch\n",
        "      display.clear_output(wait=True)\n",
        "      self.generate_and_save_images(self.generator,self.EPOCHS,test_mal_set,self.seed)'''\n",
        "                              \n",
        "                              \n",
        "\n",
        "    def generate_and_save_images(self, generator, epoch, test_mal_set,noise):\n",
        "      # Notice `training` is set to False.\n",
        "      # This is so all layers run in inference mode (batchnorm).\n",
        "      \n",
        "      predictions = generator([test_mal_set,noise], training=False)\n",
        "\n",
        "      fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "      for i in range(predictions.shape[0]):\n",
        "          plt.subplot(4, 4, i+1)\n",
        "          plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "          plt.axis('off')\n",
        "\n",
        "      plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "      plt.show()\n",
        "    \n",
        "    '''def __main__():\n",
        "      ###load the dataset####\n",
        "      uploader = UploadData()\n",
        "      train_mal_set, self.val_mal_set = uploader.upload_train_mal_set()\n",
        "      train_ben_set, self.val_ben_set = uploader.upload_train_ben_set()\n",
        "      test_mal_set = uploader.upload_test_mal_set()\n",
        "      test_ben_set = uploader.upload_test_ben_set()\n",
        "      train(train_)'''\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ypzDrwosaYHu",
        "outputId": "6e3856e8-696e-4b35-a1dc-a1a78fa7fd6e"
      },
      "source": [
        "GAN = MasterGAN(bb_detector,256, 256)\n",
        "GAN.train(dogs_train,cats_train,cats_test)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 512, 256), dtype=tf.float32, name=None), name='concatenate_8/concat:0', description=\"created by layer 'concatenate_8'\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-a35afd9ecd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMasterGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_detector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdogs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcats_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcats_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-e0cc0d98f28c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ben_images, mal_images, test_mal_set)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_mal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ben\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mben_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ben\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         '''\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Produce images for the GIF as you go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}